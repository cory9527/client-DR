{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "colab": {
   "name": "training.ipynb",
   "provenance": [],
   "include_colab_link": true
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/souravs17031999/Retinal_blindness_detection_Pytorch/blob/master/training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4lVyi6I3wp9-",
    "colab_type": "text"
   },
   "source": [
    "# Import the essentials"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "-H5XMQt5wp-B",
    "colab_type": "code",
    "outputId": "8405258a-6edb-48ef-efde-fe87e9d38934",
    "colab": {}
   },
   "source": [
    "# Imports here\n",
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils import data\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "import torchvision.models as models\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage import io, transform\n",
    "import torch.utils.data as data_utils\n",
    "from PIL import Image, ImageFile\n",
    "import json\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import os\n",
    "import argparse\n",
    "import copy\n",
    "import pandas as pd\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import cv2\n",
    "# Import useful sklearn functions\n",
    "import sklearn\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "base_dir = \"../input/aptos2019-blindness-detection/\""
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EHKTScVRwp-x",
    "colab_type": "code",
    "outputId": "aa412cf4-4dcc-4fec-b2b3-1d39e21eb7ed",
    "colab": {}
   },
   "source": [
    "print(os.listdir(\"../input/kernel4f121f3247\"))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5yxnwe8jwp-2",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import seaborn as sns"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mkb_neoqwp-6",
    "colab_type": "text"
   },
   "source": [
    "# Loading Data + EDA"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "id": "hkyWGmomwp-7",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "train_csv = pd.read_csv('../input/aptos2019-blindness-detection/train.csv')\n",
    "test_csv = pd.read_csv('../input/aptos2019-blindness-detection/test.csv')"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pkd7u6RRwp-9",
    "colab_type": "code",
    "outputId": "7fdbb7a4-25c1-43c7-f6f2-d9787b1c7ba2",
    "colab": {}
   },
   "source": [
    "print('Train Size = {}'.format(len(train_csv)))\n",
    "print('Public Test Size = {}'.format(len(test_csv)))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jgR8VptTwp_C",
    "colab_type": "code",
    "outputId": "898edfe9-0fd2-4edc-c23a-14a3b5d295be",
    "colab": {}
   },
   "source": [
    "train_csv.head()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vgygoo4Vwp_F",
    "colab_type": "code",
    "outputId": "dff17c47-0a34-45ce-ff5f-83fcf0463047",
    "colab": {}
   },
   "source": [
    "counts = train_csv['diagnosis'].value_counts()\n",
    "class_list = ['No DR', 'Mild', 'Moderate', 'Severe', 'Proliferate']\n",
    "for i,x in enumerate(class_list):\n",
    "    counts[x] = counts.pop(i)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(counts.index, counts.values, alpha=0.8, palette='bright')\n",
    "plt.title('Distribution of Output Classes')\n",
    "plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "plt.xlabel('Target Classes', fontsize=12)\n",
    "plt.show()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7jDZc3twp_H",
    "colab_type": "text"
   },
   "source": [
    "# Visualizing Training Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ax11I6Zswp_I",
    "colab_type": "code",
    "outputId": "38d1e936-008b-4703-8ea9-110ed0880eb3",
    "colab": {}
   },
   "source": [
    "fig = plt.figure(figsize=(30, 6))\n",
    "# display 20 images\n",
    "train_imgs = os.listdir(base_dir+\"/train_images\")\n",
    "for idx, img in enumerate(np.random.choice(train_imgs, 16)):\n",
    "    ax = fig.add_subplot(2, 16//2, idx+1, xticks=[], yticks=[])\n",
    "    im = Image.open(base_dir+\"/train_images/\" + img)\n",
    "    plt.imshow(im)\n",
    "    lab = train_csv.loc[train_csv['id_code'] == img.split('.')[0], 'diagnosis'].values[0]\n",
    "    ax.set_title('Severity: %s'%lab)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1tw7S3-ywp_L",
    "colab_type": "text"
   },
   "source": [
    "# Visualizing Test Set"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gmy9BNFwwp_M",
    "colab_type": "code",
    "outputId": "de5d12e0-c57c-451c-e297-5da3d12a3fbd",
    "colab": {}
   },
   "source": [
    "fig = plt.figure(figsize=(30, 6))\n",
    "# display 20 images\n",
    "test_imgs = os.listdir(base_dir+\"/test_images\")\n",
    "for idx, img in enumerate(np.random.choice(test_imgs, 16)):\n",
    "    ax = fig.add_subplot(2, 16//2, idx+1, xticks=[], yticks=[])\n",
    "    im = Image.open(base_dir+\"/test_images/\" + img)\n",
    "    plt.imshow(im)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ahpFGSqwp_O",
    "colab_type": "text"
   },
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QfvxpUdcwp_P",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Our own custom class for datasets\n",
    "class CreateDataset(Dataset):\n",
    "    def __init__(self, df_data, data_dir = '../input/', transform=None):\n",
    "        super().__init__()\n",
    "        self.df = df_data.values\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_name,label = self.df[index]\n",
    "        img_path = os.path.join(self.data_dir, img_name+'.png')\n",
    "        image = cv2.imread(img_path)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "usFGpYV9wp_R",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.4),\n",
    "    #transforms.ColorJitter(brightness=2, contrast=2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "])"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3LvQYjjzwp_U",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "test_transforms = transforms.Compose([transforms.Resize(256),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mF_yP6FVwp_W",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "train_path = \"../input/aptos2019-blindness-detection/train_images/\"\n",
    "test_path = \"../input/aptos2019-blindness-detection/test_images/\""
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rkUVBpU7wp_Z",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "train_data = CreateDataset(df_data=train_csv, data_dir=train_path, transform=train_transforms)\n",
    "test_data = CreateDataset(df_data=test_csv, data_dir=test_path, transform=test_transforms)\n",
    "    "
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BE_W-n38wp_c",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "valid_size = 0.2\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "i14OtQz0wp_e",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oSPMv1iewp_h",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64,sampler=train_sampler)\n",
    "validloader = torch.utils.data.DataLoader(train_data, batch_size=64, sampler=valid_sampler)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=64)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NvMplySzwp_j",
    "colab_type": "code",
    "outputId": "4637822a-caa7-4617-91c4-7820badd6978",
    "colab": {}
   },
   "source": [
    "print(f\"training examples contain : {len(train_data)}\")\n",
    "print(f\"testing examples contain : {len(test_data)}\")\n",
    "\n",
    "print(len(trainloader))\n",
    "print(len(validloader))\n",
    "print(len(testloader))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "I63353zewp_l",
    "colab_type": "code",
    "outputId": "229d7b10-ecaf-49bd-f25b-81816dab9a5d",
    "colab": {}
   },
   "source": [
    "# LOAD ONE BATCH OF TESTING SET TO CHECK THE IMAGES AND THEIR LABELS\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "# Checking shape of image\n",
    "print(f\"Image shape : {images.shape}\")\n",
    "print(f\"Label shape : {labels.shape}\")\n",
    "\n",
    "# denormalizing images\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UJC-bbEGwp_o",
    "colab_type": "code",
    "outputId": "420d0427-7736-460b-82da-37015f8ee195",
    "colab": {}
   },
   "source": [
    "# plotting the images of loaded batch with given fig size and frame data    \n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "grid = torchvision.utils.make_grid(images, nrow = 20, padding = 2)\n",
    "plt.figure(figsize = (20, 20))  \n",
    "plt.imshow(np.transpose(grid, (1, 2, 0)))   \n",
    "print('labels:', labels)    "
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LJ9C48WYwp_s",
    "colab_type": "code",
    "outputId": "4ebc2eea-87bd-418f-fb96-cccd50d0e62d",
    "colab": {}
   },
   "source": [
    "class_names = ['No DR', 'Mild', 'Moderate', 'Severe', 'Proliferative DR']\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "out = torchvision.utils.make_grid(images)\n",
    "imshow(out, title=[class_names[x] for x in labels])"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jqPov202wp_w",
    "colab_type": "code",
    "outputId": "67396e4a-21e5-4007-d67b-1d913cddcdab",
    "colab": {}
   },
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YWTE2JVxwp_1",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = models.resnet152(pretrained=True) \n",
    "\n",
    "num_ftrs = model.fc.in_features \n",
    "out_ftrs = 5 \n",
    "  \n",
    "model.fc = nn.Sequential(nn.Linear(num_ftrs, 512),nn.ReLU(),nn.Linear(512,out_ftrs),nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(filter(lambda p:p.requires_grad,model.parameters()) , lr = 0.00001) \n",
    "\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "model.to(device);"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "v4Hn2lk4wp_4",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "model_save_name = 'classifier.pt'\n",
    "path = F\"/kaggle/working/{model_save_name}\""
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9ETX_27awp_7",
    "colab_type": "code",
    "outputId": "b7d030e9-e9bb-4dde-d592-0c8c50167d6f",
    "colab": {}
   },
   "source": [
    "# to unfreeze more layers \n",
    "for name,child in model.named_children():\n",
    "  if name in ['layer2','layer3','layer4','fc']:\n",
    "    print(name + 'is unfrozen')\n",
    "    for param in child.parameters():\n",
    "      param.requires_grad = True\n",
    "  else:\n",
    "    print(name + 'is frozen')\n",
    "    for param in child.parameters():\n",
    "      param.requires_grad = False"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iOF-Abo-wp_-",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "optimizer = torch.optim.Adam(filter(lambda p:p.requires_grad,model.parameters()) , lr = 0.000001) \n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "G0sprIg3wqAB",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def load_model(path):\n",
    "  checkpoint = torch.load(path)\n",
    "  model.load_state_dict(checkpoint['model_state_dict'])\n",
    "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "  return model"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7gndNUYIwqAD",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "model = load_model(\"../input/kernel4f121f3247/classifier.pt\")"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JBtQWIRFwqAF",
    "colab_type": "code",
    "outputId": "c75dfe78-b90b-435e-8edb-4aaf6d011f07",
    "colab": {}
   },
   "source": [
    "model"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3LIwOcNzwqAH",
    "colab_type": "code",
    "outputId": "fc685b55-eaa3-4e71-b55b-51a0c43f19eb",
    "colab": {}
   },
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Number of trainable parameters: \\n{}\".format(pytorch_total_params))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rHB2XhSzwqAK",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def train_and_test(e):\n",
    "    epochs = e\n",
    "    train_losses , test_losses, acc = [] , [], []\n",
    "    valid_loss_min = np.Inf \n",
    "    model.train()\n",
    "    print(\"Model Training started.....\")\n",
    "    for epoch in range(epochs):\n",
    "      running_loss = 0\n",
    "      batch = 0\n",
    "      for images , labels in trainloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        batch += 1\n",
    "        if batch % 10 == 0:\n",
    "            print(f\" epoch {epoch + 1} batch {batch} completed\") \n",
    "      test_loss = 0\n",
    "      accuracy = 0\n",
    "      with torch.no_grad():\n",
    "        print(f\"validation started for {epoch + 1}\")\n",
    "        model.eval() \n",
    "        for images , labels in validloader:\n",
    "          images, labels = images.to(device), labels.to(device)\n",
    "          logps = model(images) \n",
    "          test_loss += criterion(logps,labels) \n",
    "          ps = torch.exp(logps)\n",
    "          top_p , top_class = ps.topk(1,dim=1)\n",
    "          equals = top_class == labels.view(*top_class.shape)\n",
    "          accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "      train_losses.append(running_loss/len(trainloader))\n",
    "      test_losses.append(test_loss/len(validloader))\n",
    "      acc.append(accuracy)\n",
    "      scheduler.step()\n",
    "      print(\"Epoch: {}/{}.. \".format(epoch+1, epochs),\"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader)),\"Valid Loss: {:.3f}.. \".format(test_loss/len(validloader)),\n",
    "        \"Valid Accuracy: {:.3f}\".format(accuracy/len(validloader)))\n",
    "      model.train() \n",
    "      if test_loss/len(validloader) <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,test_loss/len(validloader))) \n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model': model,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': valid_loss_min\n",
    "            }, path)\n",
    "        valid_loss_min = test_loss/len(validloader)    \n",
    "    print('Training Completed Succesfully !')    \n",
    "    return train_losses, test_losses, acc "
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9X7zW47awqAM",
    "colab_type": "code",
    "outputId": "d514b4d2-f42e-4991-f326-ec1c68056c6d",
    "colab": {}
   },
   "source": [
    "train_losses, valid_losses, acc = train_and_test(5)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zq572wFDwqAO",
    "colab_type": "code",
    "outputId": "b12538f5-6eef-4284-b7af-7bca45cabb9f",
    "colab": {}
   },
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "plt.plot(train_losses, label='train_')\n",
    "plt.plot(valid_losses, label='Validation loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(frameon=False)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "14JeIrsSwqAR",
    "colab_type": "code",
    "outputId": "98493497-4844-4615-a872-d9d2e367d412",
    "colab": {}
   },
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "plt.plot(acc, label='accuracy')\n",
    "plt.legend(\"\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend(frameon=False)"
   ],
   "execution_count": 0,
   "outputs": []
  }
 ]
}
